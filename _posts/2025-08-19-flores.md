---
title : "FLORES"

---

1. [ FLORES: A Reconfigured Wheel-Legged Robot
 for Enhanced Steering and Adaptability](https://arxiv.org/pdf/2507.22345)，这个论文是国人写的，我想看看里面的内容。
2. V. Klemm, A. Morra, C. Salzmann, F. Tschopp, K. Bodie, L. Gulich, N. K ̈ung, D. Mannhart, C. Pfister, M. Vierneisel et al., “Ascento: A two-wheeled jumping robot,” in 2019 International Conference on Robotics and Automation, 2019, pp. 7515–7521. 这段文字应该是引用吧。看不懂”pp.“的意思。

    问了GPT：上面的这些文字，是引用学术论文的标准格式，里面的 pp. 7515–7521 指的是 pages（页码）。
3. （2025-08-19 20:49:45）icra上的论文，都是怎么发表的？

    按照 IEEE ICRA 模板 写论文（通常 6 页），提出原创性且有价值的创新就可以发表。每篇论文会分配给 2–4 位审稿人（领域专家）。审稿人会评判论文的价值能否发表。
4. 看了论文的第一页，意思就是说，这篇论文 提出，给机器狗狗造型的轮足bot改进一个功能（肩关节可以偏航），就可以有效增加狗狗的机动性？
5. 为什么机器人控制常用 50 Hz？

    这里的 50 Hz 指的是 高层控制策略，比如「机器人要走直线还是转弯」。每秒 50 次已经足够流畅（20 ms 一次）。
6. Piesia TL500Z3AW-R110？？？这个狗狗用的是工业主板，搭载了i7芯片的工业主板。

    搜了一下，工业主板（Piesia TL500Z3AW-R110）设计用于 7×24 小时不间断运行，抗干扰、电磁兼容性更好。而且主板往往自带 串口（RS-232/422/485）、CAN 总线、GPIO、PCIe Mini 卡等，方便和传感器/执行器/控制总线对接。而且工业主板供货稳定，这一点不错。
7. reward function这个是什么？

    在强化学习中，Reward Function（奖励函数） 是用来告诉智能体（比如机器人）它的行为“好不好”的规则。
8. 好像看到论文的核心了。这个改进的狗狗，使用了 强化学习 这个办法来增强性能。
    
    强化学习的输入：状态信息（689 维） → 来自 IMU、关节编码器、命令速度。

    输出：动作向量（16 维） → 控制 12 个腿部关节的角度 + 4 个轮子的速度。
9. 第一次看这类论文，收获很大。我有几个阶段性的总结：

    - 第一，是要习惯阅读大段的英文。
    - 然后是要重点关注论文是怎么验证/证明数据的。
    - 第三，想想这类论文是怎么，找到创新点的。
10. 到这里我也有几个问题。

    - 审稿人，比如这个顶会的审稿人，都有谁？
    - icra历年来最出名的几篇论文是什么？怎么评判的？
    - 宇树，额我不是那种盲目见到宇树就高呼的那种人，我只是好奇他们团队的机器狗狗 采用的一些好的办法，是不是 也对icra有借鉴？
11. 机器狗狗弹跳的公式有哪些？

    - 首先有几个参数，比如 起跳发力时间，还有弹跳高度。
    - 假设弹跳到4m(当然这太激进了)，\[\frac{1}{2}mv^2 = mgh\]这个公式
    是根据能量守恒来的，所以可以算出起跳初速度。
12. 怎么理解机器狗狗和人，都需要先弯曲关节才能起跳？

    - 人和机器狗的“下蹲起跳”动作，本质就是 先储存能量 → 再把能量转化为动能，完全是能量守恒的体现。
    - 人类下蹲时，肌肉收缩并储存化学能（ATP 提供的能量 + 肌腱像弹簧一样储存部分弹性能）。
    - 那么推断机器狗狗要想实现起跳，肯定要有个液压系统或者弹簧系统。
13. 

